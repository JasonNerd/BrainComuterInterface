# Pattern Recognition and Machine Learning (PRML)

![MDN](https://i.imgur.com/2uCUY3q.png)

[![nbviewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/gerdm/prml/tree/master/)


This project contains Jupyter notebooks of many the algorithms presented in Christopher Bishop's Pattern Recognition and Machine Learning book, as well as replicas for many of the graphs presented in the book.

## Discussions (new)
If you have any questions and/or requests, check out the [discussions](https://github.com/gerdm/prml/discussions) page!

## Useful Links
* [PRML Book](https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning)
* [Matrix Calculus](http://www.matrixcalculus.org/matrixCalculus)
* [The Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)
* [PRML Errata](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/prml-errata-1st-20110921.pdf)
* [More PRML Errata (repo)](https://github.com/yousuketakada/prml_errata)

## Content
```
.
├── README.md
├── chapter01
│   ├── einsum.ipynb
│   ├── exercises.ipynb
│   └── introduction.ipynb
├── chapter02
│   ├── Exercises.ipynb
│   ├── bayes-binomial.ipynb
│   ├── bayes-normal.ipynb
│   ├── density-estimation.ipynb
│   ├── exponential-family.ipynb
│   ├── gamma-distribution.ipynb
│   ├── mixtures-of-gaussians.ipynb
│   ├── periodic-variables.ipynb
│   ├── robbins-monro.ipynb
│   └── students-t-distribution.ipynb
├── chapter03
│   ├── bayesian-linear-regression.ipynb
│   ├── equivalent-kernel.ipynb
│   ├── evidence-approximation.ipynb
│   ├── linear-models-for-regression.ipynb
│   ├── ml-vs-map.ipynb
│   ├── predictive-distribution.ipynb
│   └── sequential-bayesian-learning.ipynb
├── chapter04
│   ├── exercises.ipynb
│   ├── fisher-linear-discriminant.ipynb
│   ├── least-squares-classification.ipynb
│   ├── logistic-regression.ipynb
│   └── perceptron.ipynb
├── chapter05
│   ├── backpropagation.ipynb
│   ├── bayesian-neural-networks.ipynb
│   ├── ellipses.ipynb
│   ├── imgs
│   │   └── f51.png
│   ├── mixture-density-networks.ipynb
│   ├── soft-weight-sharing.ipynb
│   └── weight-space-symmetry.ipynb
├── chapter06
│   ├── gaussian-processes.ipynb
│   └── kernel-regression.ipynb
├── chapter07
│   ├── relevance-vector-machines.ipynb
│   └── support-vector-machines.ipynb
├── chapter08
│   ├── exercises.ipynb
│   ├── graphical-model-inference.ipynb
│   ├── img.jpeg
│   ├── markov-random-fields.ipynb
│   ├── sum-product.ipynb
│   └── trees.ipynb
├── chapter09
│   ├── gaussian-mixture-models.ipynb
│   ├── k-means.ipynb
│   └── mixture-of-bernoulli.ipynb
├── chapter10
│   ├── exponential-mixture-gaussians.ipynb
│   ├── local-variational-methods.ipynb
│   ├── mixture-gaussians.ipynb
│   ├── variational-logistic-regression.ipynb
│   └── variational-univariate-gaussian.ipynb
├── chapter11
│   ├── adaptive-rejection-sampling.ipynb
│   ├── gibbs-sampling.ipynb
│   ├── hybrid-montecarlo.ipynb
│   ├── markov-chain-motecarlo.ipynb
│   ├── rejection-sampling.ipynb
│   ├── slice-sampling.ipynb
│   └── transformation-random-variables.ipynb
├── chapter12
│   ├── bayesian-pca.ipynb
│   ├── kernel-pca.ipynb
│   ├── ppca.py
│   ├── principal-component-analysis.ipynb
│   └── probabilistic-pca.ipynb
├── chapter13
│   ├── em-hidden-markov-model.ipynb
│   ├── hidden-markov-model.ipynb
│   └── linear-dynamical-system.ipynb
├── chapter14
│   ├── CART.ipynb
│   ├── boosting.ipynb
│   ├── cmm-linear-regression.ipynb
│   ├── cmm-logistic-regression.ipynb
│   └── tree.py
└── misc
    └── tikz
        ├── ch13-hmm.tex
        └── ch8-sum-product.tex

17 directories, 73 files
```
