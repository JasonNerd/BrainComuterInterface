{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This notebook takes a previously trained RNN and evaluates it on held-out data, saving the outputs for later processing.\n",
    "#We also compute here the overall character error rate and word error rate across all held-out data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#suppress all tensorflow warnings (largely related to compatability with v2)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from charSeqRNN import charSeqRNN, getDefaultRNNArgs\n",
    "\n",
    "#point this towards the top level dataset directory\n",
    "rootDir = os.path.expanduser('~') + '/handwritingBCIData/'\n",
    "\n",
    "#evaluate the RNN on these datasets\n",
    "dataDirs = ['t5.2019.05.08','t5.2019.11.25','t5.2019.12.09','t5.2019.12.11','t5.2019.12.18',\n",
    "            't5.2019.12.20','t5.2020.01.06','t5.2020.01.08','t5.2020.01.13','t5.2020.01.15']\n",
    "\n",
    "#use this train/test partition\n",
    "cvPart = 'HeldOutTrials'\n",
    "\n",
    "#point this towards the specific RNN we want to evaluate\n",
    "rnnOutputDir = cvPart\n",
    "\n",
    "#this prevents tensorflow from taking over more than one gpu on a multi-gpu machine\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "#this is where we're going to save the RNN outputs\n",
    "inferenceSaveDir = rootDir+'RNNTrainingSteps/Step5_RNNInference/' + rnnOutputDir\n",
    "\n",
    "if not os.path.isdir(rootDir + 'RNNTrainingSteps/Step5_RNNInference'):\n",
    "    os.mkdir(rootDir + 'RNNTrainingSteps/Step5_RNNInference')\n",
    "    \n",
    "if not os.path.isdir(inferenceSaveDir):\n",
    "    os.mkdir(inferenceSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Processing dataset t5.2019.05.08\n",
      "Loading from checkpoint: /home/fwillett/handwritingDatasetsForRelease/ProcessedData/Step4_RNNTraining/HeldOutTrials/model.ckpt-100000\n",
      "Starting inference.\n",
      "Done with inference.\n",
      " \n",
      "Processing dataset t5.2019.11.25\n",
      "Loading from checkpoint: /home/fwillett/handwritingDatasetsForRelease/ProcessedData/Step4_RNNTraining/HeldOutTrials/model.ckpt-100000\n",
      "Starting inference.\n",
      "Done with inference.\n",
      " \n",
      "Processing dataset t5.2019.12.09\n",
      "Loading from checkpoint: /home/fwillett/handwritingDatasetsForRelease/ProcessedData/Step4_RNNTraining/HeldOutTrials/model.ckpt-100000\n",
      "Starting inference.\n",
      "Done with inference.\n",
      " \n",
      "Processing dataset t5.2019.12.11\n",
      "Loading from checkpoint: /home/fwillett/handwritingDatasetsForRelease/ProcessedData/Step4_RNNTraining/HeldOutTrials/model.ckpt-100000\n",
      "Starting inference.\n",
      "Done with inference.\n",
      " \n",
      "Processing dataset t5.2019.12.18\n",
      "Loading from checkpoint: /home/fwillett/handwritingDatasetsForRelease/ProcessedData/Step4_RNNTraining/HeldOutTrials/model.ckpt-100000\n",
      "Starting inference.\n",
      "Done with inference.\n",
      " \n",
      "Processing dataset t5.2019.12.20\n",
      "Loading from checkpoint: /home/fwillett/handwritingDatasetsForRelease/ProcessedData/Step4_RNNTraining/HeldOutTrials/model.ckpt-100000\n",
      "Starting inference.\n",
      "Done with inference.\n",
      " \n",
      "Processing dataset t5.2020.01.06\n",
      "Loading from checkpoint: /home/fwillett/handwritingDatasetsForRelease/ProcessedData/Step4_RNNTraining/HeldOutTrials/model.ckpt-100000\n",
      "Starting inference.\n",
      "Done with inference.\n",
      " \n",
      "Processing dataset t5.2020.01.08\n",
      "Loading from checkpoint: /home/fwillett/handwritingDatasetsForRelease/ProcessedData/Step4_RNNTraining/HeldOutTrials/model.ckpt-100000\n",
      "Starting inference.\n",
      "Done with inference.\n",
      " \n",
      "Processing dataset t5.2020.01.13\n",
      "Loading from checkpoint: /home/fwillett/handwritingDatasetsForRelease/ProcessedData/Step4_RNNTraining/HeldOutTrials/model.ckpt-100000\n",
      "Starting inference.\n",
      "Done with inference.\n",
      " \n",
      "Processing dataset t5.2020.01.15\n",
      "Loading from checkpoint: /home/fwillett/handwritingDatasetsForRelease/ProcessedData/Step4_RNNTraining/HeldOutTrials/model.ckpt-100000\n",
      "Starting inference.\n",
      "Done with inference.\n"
     ]
    }
   ],
   "source": [
    "#Configures the RNN for inference mode.\n",
    "args = getDefaultRNNArgs()\n",
    "\n",
    "args['outputDir'] = rootDir+'RNNTrainingSteps/Step4_RNNTraining/'+rnnOutputDir\n",
    "args['loadDir'] = args['outputDir']\n",
    "args['mode'] = 'infer'\n",
    "args['timeSteps'] = 7500 #Need to specify enough time steps so that the longest sentence fits in the minibatch\n",
    "args['batchSize'] = 2 #Process just two sentences at a time, to make sure we have enough memory\n",
    "args['synthBatchSize'] = 0 #turn off synthetic data here, we are only using real data\n",
    "\n",
    "#Proceeds one dataset at a time. Currently the code is setup to only process a single dataset at inference time,\n",
    "#so we have to rebuild the graph for each dataset.\n",
    "for x in range(len(dataDirs)):\n",
    "    #configure the RNN to process this particular dataset\n",
    "    print(' ')\n",
    "    print('Processing dataset ' + dataDirs[x])\n",
    "    \n",
    "    args['sentencesFile_0'] = rootDir+'Datasets/'+dataDirs[x]+'/sentences.mat'\n",
    "    args['singleLettersFile_0'] = rootDir+'Datasets/'+dataDirs[x]+'/singleLetters.mat'\n",
    "    args['labelsFile_0'] = rootDir+'RNNTrainingSteps/Step2_HMMLabels/'+cvPart+'/'+dataDirs[x]+'_timeSeriesLabels.mat'\n",
    "    args['syntheticDatasetDir_0'] = rootDir+'RNNTrainingSteps/Step3_SyntheticSentences/'+cvPart+'/'+dataDirs[x]+'_syntheticSentences/'\n",
    "    args['cvPartitionFile_0'] = rootDir+'RNNTrainingSteps/trainTestPartitions_'+cvPart+'.mat'\n",
    "    args['sessionName_0'] = dataDirs[x]\n",
    "\n",
    "    args['inferenceOutputFileName'] = inferenceSaveDir + '/' + dataDirs[x] + '_inferenceOutputs.mat'\n",
    "    args['inferenceInputLayer'] = x\n",
    "    \n",
    "    #instantiate the RNN model\n",
    "    rnnModel = charSeqRNN(args=args)\n",
    "\n",
    "    #evaluate the RNN on the held-out data\n",
    "    outputs = rnnModel.inference()\n",
    "    \n",
    "    #reset the graph to make space for the next dataset\n",
    "    tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- t5.2019.05.08 --\n",
      "Character error rate for this session: 3.17%\n",
      "Below is the decoder output for all validation sentences in this session:\n",
      " \n",
      "#2:\n",
      "True:    you want me to sing?\n",
      "Decoded: you want me to ssng?\n",
      " \n",
      "#5:\n",
      "True:    have you ever seen a large cat fold itself into a tiny shoe box?\n",
      "Decoded: have you ever seen a large cat fold itself into a tiny shoe box?\n",
      " \n",
      "#21:\n",
      "True:    the jeep was thirsty so i stopped for gas on the edge of town.\n",
      "Decoded: the jeep was thirsty so i sfopped for gas on the edge ef town.\n",
      " \n",
      "#33:\n",
      "True:    because less than a quarter mile from where i'm standing right now is where alla's body was dumped.\n",
      "Decoded: because less than a quarter mle frrrom where i'm standng right now is where alla's body waas dumped.\n",
      " \n",
      "#34:\n",
      "True:    there are moments when gentle background singing brings the song close to gospel.\n",
      "Decoded: there are moments when gentle  background singinig brings the song closeto gospel.\n",
      " \n",
      "#39:\n",
      "True:    so you could literally see here's what every single person in the company gets paid.\n",
      "Decoded: so you coud literally see here's what eevery single person in the comphny gets paid.\n",
      " \n",
      "#54:\n",
      "True:    i told you we were going to bring this sucker home, and we brought it home.\n",
      "Decoded: i told you we were going to bring this sucker home, and we brought it home.\n",
      " \n",
      "#90:\n",
      "True:    what rent do you pay for your housing?\n",
      "Decoded: what rent do you pay for your housing?\n",
      " \n",
      "#91:\n",
      "True:    plainly, there is a clear and present need to secure information in the public and private sectors.\n",
      "Decoded: phainly, there is a clear andpresent heed to secure information in the pullic and private sectors.\n",
      " \n",
      "#98:\n",
      "True:    i thought i could fix it but got trapped by my ego and refusal to fail.\n",
      "Decoded: i ihousht i could fr  it but got trapped by my ego and refusal to fail.\n",
      " \n",
      "-- t5.2019.11.25 --\n",
      "Character error rate for this session: 3.51%\n",
      "Below is the decoder output for all validation sentences in this session:\n",
      " \n",
      "#5:\n",
      "True:    then it wobbled under her weight and tilted forwards.\n",
      "Decoded: then it wobbled under her weiight and tilted forwards.\n",
      " \n",
      "#21:\n",
      "True:    and my brother's in hong kong all that week.\n",
      "Decoded: and hyhyrother's in hong kong all that week.\n",
      " \n",
      "#31:\n",
      "True:    then we slipped into the kitchen , got up on the sink, and hauled ourselves into the little attic.\n",
      "Decoded: then we slipped into the kitchen , got up on the sink, and hacled ourselves into the little attic.\n",
      " \n",
      "#33:\n",
      "True:    he didn't like being tied up to the women.\n",
      "Decoded: he didn't like being tiedd up to the women.\n",
      " \n",
      "#34:\n",
      "True:    you can rent money.\n",
      "Decoded: xou can rent money.\n",
      " \n",
      "#39:\n",
      "True:    the only peace that you'll find here lies in a kind of pagan solitude.\n",
      "Decoded: the only peace that you'll find here lies in a kind of pagan solltude.\n",
      " \n",
      "#61:\n",
      "True:    his pot was in his hand still, it preceded him like the torch of justice.\n",
      "Decoded: his pot was in his hand still, iffroeceded lm like the torch of justice.\n",
      " \n",
      "-- t5.2019.12.09 --\n",
      "Character error rate for this session: 2.76%\n",
      "Below is the decoder output for all validation sentences in this session:\n",
      " \n",
      "#5:\n",
      "True:    maybe get your horses to swim across.\n",
      "Decoded: mai,be get your horses to swim across.\n",
      " \n",
      "#21:\n",
      "True:    i thought they were staying the night.\n",
      "Decoded: i thought they were staying the nightw\n",
      " \n",
      "#31:\n",
      "True:    it seemed a poor thing to have descended to.\n",
      "Decoded: tt seemed a poor thing to have descended to.\n",
      " \n",
      "#33:\n",
      "True:    his sudden talk of alibis made the whole thing sound serious.\n",
      "Decoded: uhis sudden talk of alipis made the whoole thing sound serious.\n",
      " \n",
      "#34:\n",
      "True:    is the policy still to sit it out and wait rather than try and force your way into the prison?\n",
      "Decoded: is the bolicy stiill to sit it out and wait rather than try and force your way into the prison?\n",
      " \n",
      "#39:\n",
      "True:    i accept that it precludes class a development.\n",
      "Decoded: i accept that it preeludes class a development.\n",
      " \n",
      "#68:\n",
      "True:    at that moment she heard rapid footsteps.\n",
      "Decoded: at that moment she heard rapid footsteps.\n",
      " \n",
      "-- t5.2019.12.11 --\n",
      "Character error rate for this session: 1.46%\n",
      "Below is the decoder output for all validation sentences in this session:\n",
      " \n",
      "#5:\n",
      "True:    but i have to hear the whole tale.\n",
      "Decoded: pot i have to hear the whole tale.\n",
      " \n",
      "#21:\n",
      "True:    this fuzzy, probabilistic approach is a sensible one.\n",
      "Decoded: this fuzzy, probabilistic approach is a sensible one.\n",
      " \n",
      "#31:\n",
      "True:    he needed to develop his mind.\n",
      "Decoded: he needed to develop his mind.\n",
      " \n",
      "#33:\n",
      "True:    people here are also adopting a healthier diet.\n",
      "Decoded: people here are also adopting a healthier diet.\n",
      " \n",
      "#34:\n",
      "True:    the royal navy had left its mark.\n",
      "Decoded: the royal navy had left its mark.\n",
      " \n",
      "#39:\n",
      "True:    a long shower relaxed her still further.\n",
      "Decoded: a long shower releyed her still further.\n",
      " \n",
      "#61:\n",
      "True:    thrown in nuts and carrots and blend.\n",
      "Decoded: thrown in nuts and carrots and blend.\n",
      " \n",
      "-- t5.2019.12.18 --\n",
      "Character error rate for this session: 1.99%\n",
      "Below is the decoder output for all validation sentences in this session:\n",
      " \n",
      "#5:\n",
      "True:    he lifted his hand out of the water to smooth his hair.\n",
      "Decoded: he lifted his hand out of the water to smooth his hair.\n",
      " \n",
      "#21:\n",
      "True:    the servants would know whether it was possible to get back down the valley.\n",
      "Decoded: the servants would know whether it was possible to get back down the valley.\n",
      " \n",
      "#31:\n",
      "True:    why are you prepared to play such a desperate game, to put your whole future in jeopardy like this?\n",
      "Decoded: why ar you prepard to play such adeaperate game, to put your whole future in jeopardy like this?\n",
      " \n",
      "#33:\n",
      "True:    you had round red cheeks, just like a wooden doll.\n",
      "Decoded: you had round red cheeks, just like a wooden doll.\n",
      " \n",
      "#34:\n",
      "True:    i have seven apples, seven oranges and seven bananas.\n",
      "Decoded: i have sever apples, seven oranges and seven banaras.\n",
      " \n",
      "#39:\n",
      "True:    grumpy wizards make a toxic brew for the jovial queen.\n",
      "Decoded: grumpy wizards make a toxic brew for the jovicl queen.\n",
      " \n",
      "#61:\n",
      "True:    he reckons his success on the field depends on learning the lingo.\n",
      "Decoded: he reckons his suceess on the fielddepends on learning the lingo.\n",
      " \n",
      "-- t5.2019.12.20 --\n",
      "Character error rate for this session: 1.60%\n",
      "Below is the decoder output for all validation sentences in this session:\n",
      " \n",
      "#5:\n",
      "True:    i'm not tough enough to toe the line.\n",
      "Decoded: i'm not touugh enough to toe the line.\n",
      " \n",
      "#21:\n",
      "True:    a lot of old folk are getting caught and we must stamp it out.\n",
      "Decoded: q lot of old folk are getting caught and we must stamp it out.\n",
      " \n",
      "#31:\n",
      "True:    these agents are now being tested in clinical trials with people at risk.\n",
      "Decoded: these agents are now being tested in clinical trials with people at risk.\n",
      " \n",
      "#33:\n",
      "True:    the way he said it made the name sound like orchids and honey.\n",
      "Decoded: the way he said it made the name sound like orchids and herey.\n",
      " \n",
      "#34:\n",
      "True:    pack my box with five dozen liquor jugs.\n",
      "Decoded: pack my box with five dozen liquor jugs.\n",
      " \n",
      "#39:\n",
      "True:    state officials are always under threat, always being kidnapped.\n",
      "Decoded: state officials are always under threat, always being lidnapped.\n",
      " \n",
      "#61:\n",
      "True:    that's when i threw up on the carpet.\n",
      "Decoded: that's whenn i threw up on the carpet.\n",
      " \n",
      "-- t5.2020.01.06 --\n",
      "Character error rate for this session: 2.56%\n",
      "Below is the decoder output for all validation sentences in this session:\n",
      " \n",
      "#5:\n",
      "True:    they breathe air and they cannot swim.\n",
      "Decoded: they breathe air and they canrot swim.\n",
      " \n",
      "#21:\n",
      "True:    from the terrace, a broad flight of central steps led down to lawns and formal flowerbeds.\n",
      "Decoded: from the terroce, a proad flight of central steps led dowwn to lawns and formal flowerbeds.\n",
      " \n",
      "#31:\n",
      "True:    the corpses lay uncovered in the open on plastic sheets.\n",
      "Decoded: the corpses lay uncovered in the open on plastic sheeets.\n",
      " \n",
      "#39:\n",
      "True:    shame on us for not caring.\n",
      "Decoded: shame on us for not caring.\n",
      " \n",
      "#61:\n",
      "True:    the other battalions were infected by the panic and also fled.\n",
      "Decoded: the other battalions were infected bythe panic aand also fled.\n",
      " \n",
      "-- t5.2020.01.08 --\n",
      "Character error rate for this session: 2.84%\n",
      "Below is the decoder output for all validation sentences in this session:\n",
      " \n",
      "#5:\n",
      "True:    on the eve of the council the worst of horrors was revealed.\n",
      "Decoded: on the eve of tthe council the worsst of horrons was revealed.\n",
      " \n",
      "#21:\n",
      "True:    a small coal fire burned in the grate.\n",
      "Decoded: a small coal fire burned in the grate.\n",
      " \n",
      "#31:\n",
      "True:    the result is a lighter weight fabric, but one which still shows off the yarn.\n",
      "Decoded: the resut is a lighter weight fabric, but one whichh still shows off the yarn.\n",
      " \n",
      "#33:\n",
      "True:    perhaps they would accept his old currency.\n",
      "Decoded: perhaps they would accept his olld cunreney.\n",
      " \n",
      "#34:\n",
      "True:    already the grass was becoming crisp with frost.\n",
      "Decoded: already the grass was becoming crisp with frost.\n",
      " \n",
      "#39:\n",
      "True:    it is the necessary foundation for growth of small businesses.\n",
      "Decoded: it is the necessary foundation for growth of small businesses.\n",
      " \n",
      "#61:\n",
      "True:    celia constantly refers to her mother's drowning accident.\n",
      "Decoded: celia constantly refere to her mothes drowning accident.\n",
      " \n",
      "-- t5.2020.01.13 --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character error rate for this session: 6.43%\n",
      "Below is the decoder output for all validation sentences in this session:\n",
      " \n",
      "#22:\n",
      "True:    crazy frederick bought many very exquisite opal jewels.\n",
      "Decoded: crany frderick broousht many very exquisite opal jewwels.\n",
      " \n",
      "#25:\n",
      "True:    sphinx of black quartz, judge my vow.\n",
      "Decoded: sphinx of black quartz,, udge my vow.\n",
      " \n",
      "#121:\n",
      "True:    residents were warned to prepare flood defences.\n",
      "Decoded: residents were warned to rrepare flood defences.\n",
      " \n",
      "-- t5.2020.01.15 --\n",
      "Character error rate for this session: 3.91%\n",
      "Below is the decoder output for all validation sentences in this session:\n",
      " \n",
      "#22:\n",
      "True:    imagine a star with a mass ten times that of the sun.\n",
      "Decoded: imagine a star with a mass ten times that of the son.\n",
      " \n",
      "#25:\n",
      "True:    the elder boys are not deterred, however.\n",
      "Decoded: the alder boys ar not deterred,, however.\n",
      " \n",
      "#121:\n",
      "True:    you never used to swear, you know.\n",
      "Decoded: you hever used to swear, you know.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#This cell loads the outputs produced above and computes character error counts and word error counts.\n",
    "from characterDefinitions import getHandwritingCharacterDefinitions\n",
    "from rnnEval import evaluateRNNOutput, rnnOutputToKaldiMatrices\n",
    "import warnings\n",
    "\n",
    "#this stops scipy.io.savemat from throwing a warning about empty entries\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "charDef = getHandwritingCharacterDefinitions()\n",
    "allErrCounts = []\n",
    "\n",
    "for x in range(len(dataDirs)):\n",
    "    print('-- ' + dataDirs[x] + ' --')\n",
    "    \n",
    "    #Load up the outputs, which are frame-by-frame probabilities. \n",
    "    outputs = scipy.io.loadmat(inferenceSaveDir + '/' + dataDirs[x] + '_inferenceOutputs.mat')\n",
    "    sentenceDat = scipy.io.loadmat(rootDir+'Datasets/'+dataDirs[x]+'/sentences.mat')\n",
    "    \n",
    "    #Convert the outputs into character sequences (with simple thresholding) & get word/character error counts.\n",
    "    errCounts, decSentences = evaluateRNNOutput(outputs['outputs'], \n",
    "                                        sentenceDat['numTimeBinsPerSentence']/2 + 50, \n",
    "                                        sentenceDat['sentencePrompt'], \n",
    "                                        charDef, \n",
    "                                        charStartThresh=0.3, \n",
    "                                        charStartDelay=15)\n",
    "    \n",
    "    #save decoded sentences, character error rates and word error rates for later summarization\n",
    "    saveDict = {}\n",
    "    saveDict['decSentences'] = decSentences\n",
    "    saveDict['trueSentences'] = sentenceDat['sentencePrompt']\n",
    "    saveDict.update(errCounts)\n",
    "    \n",
    "    scipy.io.savemat(inferenceSaveDir + '/' + dataDirs[x] + '_errCounts.mat', saveDict)\n",
    "    \n",
    "    #print results for the validation sentences\n",
    "    cvPartFile = scipy.io.loadmat(rootDir+'RNNTrainingSteps/trainTestPartitions_'+cvPart+'.mat')\n",
    "    valIdx = cvPartFile[dataDirs[x]+'_test']\n",
    "    \n",
    "    if len(valIdx)==0:\n",
    "        print('No validation sentences for this session.')\n",
    "        print('  ')\n",
    "        continue\n",
    "            \n",
    "    valAcc = 100*(1 - np.sum(errCounts['charErrors'][valIdx]) / np.sum(errCounts['charCounts'][valIdx]))\n",
    "\n",
    "    print('Character error rate for this session: %1.2f%%' % float(100-valAcc))\n",
    "    print('Below is the decoder output for all validation sentences in this session:')\n",
    "    print(' ')\n",
    "    \n",
    "    for v in np.squeeze(valIdx):\n",
    "        trueText = sentenceDat['sentencePrompt'][v,0][0]\n",
    "        trueText = trueText.replace('>',' ')\n",
    "        trueText = trueText.replace('~','.')\n",
    "        trueText = trueText.replace('#','')\n",
    "        \n",
    "        print('#' + str(v) + ':')\n",
    "        print('True:    ' + trueText)\n",
    "        print('Decoded: ' + decSentences[v])\n",
    "        print(' ')\n",
    "   \n",
    "    #put together all the error counts from all sessions so we can compute overall error rates below\n",
    "    allErrCounts.append(np.stack([errCounts['charCounts'][valIdx],\n",
    "                             errCounts['charErrors'][valIdx],\n",
    "                             errCounts['wordCounts'][valIdx],\n",
    "                             errCounts['wordErrors'][valIdx]],axis=0).T)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character error rate: 2.78%\n",
      "Word error rate: 12.88%\n"
     ]
    }
   ],
   "source": [
    "#Summarize character error rate and word error rate across all sessions.\n",
    "concatErrCounts = np.squeeze(np.concatenate(allErrCounts, axis=0))\n",
    "cer = 100*(np.sum(concatErrCounts[:,1]) / np.sum(concatErrCounts[:,0]))\n",
    "wer = 100*(np.sum(concatErrCounts[:,3]) / np.sum(concatErrCounts[:,2]))\n",
    "\n",
    "print('Character error rate: %1.2f%%' % float(cer))\n",
    "print('Word error rate: %1.2f%%' % float(wer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
